---
description: Verify built features through user acceptance testing
---

# GSD Verify â€” User Acceptance Testing

Validate built features through conversational testing. Show expected behavior, ask if reality matches. One test at a time, plain text responses.

> **ğŸ›¡ï¸ ANTI-HALLUCINATION PROTOCOL â€” ACTIVE IN THIS WORKFLOW**
> Verification is the last line of defense. NEVER mark a test as "passed" without the user confirming it. NEVER infer test results â€” only the user or actual command output determines pass/fail.

## Arguments

The user should provide a phase number, e.g., `/gsd-verify 1`

## Multi-Model Safeguard: Verification Integrity

**MANDATORY â€” regardless of which AI model is running:**

```
VERIFICATION RULES:
1. NEVER auto-pass a test â€” WAIT for user's explicit response
2. NEVER assume command output â€” actually RUN commands and READ output
3. NEVER fabricate test results â€” if you can't verify, say so
4. Present ACTUAL behavior observed, not expected behavior as fact
5. If a user reports an issue, do NOT argue â€” record it exactly

âš ï¸ The most dangerous hallucination is "verification passed" when it didn't.
âš ï¸ Different models have different tendencies to agree with users or
   fabricate positive results. This protocol prevents ALL such tendencies.
```

## Steps

### 1. Validate

**Actually read** (not recall) `.planning/ROADMAP.md` and check phase exists.

**If no `.planning/`:** "No GSD project found. Run /gsd-new-project first."
**If phase not found:** "Phase [N] not found."

Check for SUMMARY.md files in the phase directory â€” these contain what was built and what to test.

**If no summaries:** "Phase [N] hasn't been executed yet. Run /gsd-execute [N] first."

### 2. Extract Testable Deliverables

**Read** (not recall) all SUMMARY.md files for this phase. For each accomplishment:

- Focus on **user-observable outcomes**, not implementation details
- Skip internal refactors, type changes, etc.
- Create a test for each deliverable with:
  - **name:** Brief test name
  - **expected:** What the user should see/experience (specific, observable)

> **ğŸ›¡ï¸ Extract tests from ACTUAL SUMMARY.md content â€” do NOT invent tests
> for features that weren't in the summary.**

Example:
- Accomplishment: "Added comment threading with infinite nesting"
  â†’ Test: "Reply to a Comment"
  â†’ Expected: "Clicking Reply opens inline composer. Submitting shows reply nested under parent."

### 3. Present Tests One at a Time

For each test, present to the user:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  TEST [N]/[Total]: [Test Name]                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Expected behavior:
[What should happen]

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†’ Type "pass" if correct, "skip" to skip, or describe what's wrong
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**WAIT for user response. Do NOT proceed to next test without explicit user input.**
**Do NOT auto-fill or suggest answers.**

### 4. Process Response

**If pass:** ("yes", "y", "ok", "pass", "next", "âœ“")
- Record as passed

**If skip:** ("skip", "can't test", "n/a")
- Record as skipped with reason

**If anything else:**
- Treat as issue description
- Record the user's EXACT words (do not paraphrase or sanitize)
- Infer severity from language:
  | User says | Severity |
  |-----------|----------|
  | crash, error, fails completely | blocker |
  | doesn't work, nothing happens, wrong | major |
  | works but..., slow, weird | minor |
  | color, spacing, alignment | cosmetic |
  | unclear | default to major |

**Never ask "how severe is this?"** â€” just infer and move on.

- Record the issue and move to next test

### 5. After All Tests

Create/update `.planning/phases/[NN]-[slug]/[NN]-UAT.md`:

```markdown
# Phase [N]: [Name] â€” User Acceptance Testing

**Started:** [date]
**Status:** complete
**Updated:** [date]

## Results

| # | Test | Result | Details |
|---|------|--------|---------|
| 1 | [Name] | âœ“ Pass | User confirmed |
| 2 | [Name] | âœ— Issue | [user's EXACT words] |
| 3 | [Name] | â—‹ Skip | [reason] |

## Summary

- **Total:** [N]
- **Passed:** [N]
- **Issues:** [N]
- **Skipped:** [N]

## Gaps

[For each issue, structured for gap-closure planning:]

- **Test [N]: [Name]**
  - Expected: [what should happen]
  - Reported: [user's exact words â€” NOT paraphrased]
  - Severity: [inferred]

---
*Tested: [date]*
```

### 6. Git Commit

```bash
git add .planning/phases/[NN]-[slug]/[NN]-UAT.md
git commit -m "test([NN]): UAT complete â€” [passed] passed, [issues] issues"
```

### 7. Completion

**If all passed:**
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 GSD â–º UAT COMPLETE âœ“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

All [N] tests passed!

## â–¶ Next Up

Recommended: Start a NEW CONVERSATION for the next phase.

/gsd-discuss [N+1]   â†’ Start next phase
/gsd-plan [N+1]      â†’ Plan next phase
```

**If issues found:**
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 GSD â–º UAT COMPLETE â€” [Issues] ISSUES FOUND
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[Passed]/[Total] tests passed. [Issues] issues need attention:

[List each issue with severity]

## â–¶ Next Up

/gsd-plan [N]        â†’ Re-plan to fix gaps
```
